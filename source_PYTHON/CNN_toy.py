import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib as mpl

w = [1]
label_size = 30
mpl.rcParams['xtick.labelsize'] = label_size
mpl.rcParams['ytick.labelsize'] = label_size


FILTER_SIZE = 5

#50cm
rss = [[50, "-34	-37	-62	-59	-61	-62	-63	-62	-62	-61	-67	-61	-60	-66	-63	-71	-66	-63	-62	-58	-63	-62	-60	-59	-62	-64	-64	-61	-60	-61	-63	-70	-71	-56	-70	-60	-59	-73	-57	-66	-57	-58	-65	-69	-57	-40	-37	-63	-69	-59	-60	-60	-60	-60	-61	-59	-60	-60	-64	-61	-66	-61	-61	-59	-59	-60	-60	-60	-61	-60	-60	-61	-59	-58	-58	-65	-65	-63	-65	-61	-64	-58	-58	-62	-66	-62	-61	-60	-61	-62	-60	-62	-61	-62	-64	-62	-62	-64	-66	-62	-64	-60	-65	-60	-61	-60	-63	-62	-62	-60	-60	-62	-62	-63	-58	-59	-60	-61	-59	-68	-68	-60	-68	-61	-62	-62	-59	-59	-67	-60	-61	-60	-63	-62	-58	-60	-60	-61	-64	-59	-61	-61	-62	-60	-63	-62	-60	-62	-67	-60	-60	-65	-60	-66	-60	-60	-62	-64	-63	-62	-60	-61	-60	-66	-60	-60	-60	-68	-60	-64	-60	-59	-66	-60	-64	-66	-60	-65	-63	-60	-60	-61	-62	-62	-60	-62	-59	-62	-61	-60	-62	-67	-61	-61	-61	-62	-62	-60	-60	-64	-62	-60	-62	-60	-62	-65	-63	-61	-60	-59"],
       [80, "-62	-60	-63	-65	-60	-63	-59	-66	-69	-64	-62	-65	-67	-67	-66	-63	-63	-66	-64	-65	-63	-64	-65	-61	-61	-59	-61	-62	-64	-64	-59	-61	-63	-63	-61	-60	-62	-62	-62	-64	-64	-64	-63	-63	-63	-62	-60	-65	-64	-60	-60	-65	-66	-59	-63	-65	-64	-64	-64	-65	-67	-70	-62	-62	-62	-69	-62	-62	-62	-62	-67	-66	-66	-59	-66	-59	-66	-62	-67	-66	-60	-65	-66	-61	-62	-60	-62	-62	-63	-65	-67	-63	-64	-62	-59	-62	-62	-63	-63	-60	-64	-62	-64	-58	-62	-61	-60	-64	-64	-72	-63	-69	-64	-67	-61	-63	-70	-62	-69	-65	-62	-63	-64	-60	-63	-63	-60	-64	-60	-62	-61	-64	-64	-61	-64	-60	-64	-63	-62	-62	-62	-62	-60	-61	-62	-64	-63	-64	-62	-65	-64	-63	-61	-62	-62	-62	-61	-62	-62	-61	-61	-60	-67	-75	-62	-62	-67	-61	-66	-60	-61	-65	-69	-82	-62	-62	-61	-62	-63	-61	-64	-60	-64	-65	-64	-62	-62	-66	-66	-60	-63	-62	-62	-62	-60	-60	-63	-65	-63	-60	-66	-61	-66	-60	-62	-65	-63	-61	-60	-59"],
       [120, "-61	-63	-68	-67	-69	-74	-60	-60	-64	-64	-60	-60	-62	-67	-60	-60	-60	-66	-67	-67	-67	-81	-70	-60	-60	-67	-62	-71	-69	-63	-72	-71	-70	-73	-61	-64	-66	-67	-62	-61	-60	-66	-67	-67	-61	-65	-64	-70	-70	-73	-61	-67	-62	-66	-68	-61	-68	-67	-68	-66	-68	-67	-66	-83	-60	-68	-62	-75	-63	-63	-63	-63	-64	-63	-63	-66	-63	-63	-60	-63	-63	-62	-62	-77	-76	-79	-62	-62	-76	-61	-63	-61	-74	-74	-68	-68	-62	-68	-68	-70	-66	-61	-67	-67	-68	-61	-74	-64	-73	-71	-62	-61	-61	-62	-75	-72	-73	-63	-70	-69	-69	-62	-62	-67	-70	-72	-73	-68	-61	-61	-68	-61	-60	-60	-60	-67	-67	-67	-61	-60	-60	-69	-70	-60	-61	-68	-69	-60	-60	-64	-61	-62	-69	-60	-62	-62	-61	-75	-73	-69	-69	-77	-75	-61	-61	-66	-67	-67	-66	-61	-67	-67	-70	-60	-70	-62	-69	-69	-70	-69	-67	-67	-61	-68	-69	-69	-69	-70	-69	-62	-67	-67	-66	-62	-73	-66	-65	-67	-63	-63	-68	-75	-60	-61	-89	-76	-62	-60	-60	-62	-62	-67	-61	-60	-84	-67	-68	-66	-59	-66	-61	-67	-60	-62	-61	-69"],
       [160, "-40	-66	-75	-75	-65	-78	-68	-63	-63	-66	-64	-88	-62	-62	-70	-64	-63	-61	-61	-62	-62	-65	-62	-62	-63	-61	-79	-60	-62	-61	-62	-61	-68	-68	-67	-66	-82	-60	-86	-60	-71	-71	-69	-58	-66	-65	-61	-60	-62	-62	-63	-60	-60	-60	-62	-72	-63	-60	-62	-70	-63	-60	-66	-66	-69	-66	-70	-72	-72	-69	-67	-69	-68	-65	-65	-68	-77	-77	-73	-65	-76	-64	-64	-64	-64	-64	-63	-64	-67	-62	-60	-60	-61	-61	-63	-62	-61	-61	-61	-60	-72	-61	-61	-60	-75	-70	-73	-66	-73	-72	-71	-65	-64	-64	-63	-62	-62	-63	-63	-63	-62	-62	-62	-62	-63	-63	-62	-68	-64	-62	-60	-59	-64	-64	-69	-64	-62	-64	-64	-64	-67	-67	-60	-63	-63	-67	-61	-61	-65	-62	-62	-63	-67	-71	-70	-68	-68	-66	-61	-61	-70	-61	-72	-61	-78	-77	-61	-62	-62	-62	-71	-62	-62	-63	-62	-63	-61	-70	-64	-65	-64	-64	-62	-61	-62	-62	-64	-62	-71	-70	-61	-62	-61	-62	-62	-71	-70	-67	-73	-67	-66	-62	-64	-75	-63	-63	-62	-63	-64	-63	-71	-61	-61	-64	-60	-62	-62	-62	-68	-62	-62	-69	-62	-62	-62	-62	-67	-72	-61	-62	-73	-69	-69	-74	-67	-67	-79	-69	-70	-74	-62	-63	-63	-64	-65	-63	-63	-76"],
       [200, "-63	-61	-62	-64	-74	-69	-70	-69	-73	-71	-67	-65	-68	-67	-67	-66	-66	-63	-68	-67	-73	-58	-72	-71	-58	-75	-70	-70	-60	-59	-58	-69	-70	-71	-65	-74	-71	-65	-58	-67	-58	-65	-66	-65	-74	-65	-67	-72	-66	-68	-63	-64	-64	-68	-68	-62	-66	-65	-66	-65	-66	-67	-65	-65	-67	-59	-58	-64	-65	-70	-64	-64	-71	-64	-64	-64	-63	-62	-70	-64	-63	-66	-41	-71	-68	-65	-72	-64	-65	-65	-65	-64	-65	-65	-67	-68	-61	-66	-66	-68	-65	-67	-68	-67	-67	-65	-62	-71	-70	-65	-64	-65	-67	-66	-66	-67	-63	-64	-65	-66	-65	-65	-68	-63	-61	-68	-67	-66	-67	-63	-65	-65	-67	-68	-61	-67	-74	-65	-58	-78	-75	-73	-69	-58	-69	-67	-67	-68	-77	-66	-58	-65	-65	-67	-68	-68	-65	-64	-68	-65	-65	-64	-67	-64	-65	-66	-66	-64	-66	-61	-66	-66	-62	-73	-67	-60	-65	-65	-64	-65	-64	-65	-67	-66	-61	-66	-61	-65	-67	-64	-66	-64	-61	-58	-66	-66	-64	-65	-69	-69	-66	-68	-67	-66	-66	-70	-66	-64	-63	-64	-67	-64	-65"],
       [240, "-63	-61	-62	-64	-74	-69	-70	-69	-73	-71	-67	-65	-68	-67	-67	-66	-66	-63	-68	-67	-73	-58	-72	-71	-58	-75	-70	-70	-60	-59	-58	-69	-70	-71	-65	-74	-71	-65	-58	-67	-58	-65	-66	-65	-74	-65	-67	-72	-66	-68	-63	-64	-64	-68	-68	-62	-66	-65	-66	-65	-66	-67	-65	-65	-67	-59	-58	-64	-65	-70	-64	-64	-71	-64	-64	-64	-63	-62	-70	-64	-63	-66	-41	-71	-68	-65	-72	-64	-65	-65	-65	-64	-65	-65	-67	-68	-61	-66	-66	-68	-65	-67	-68	-67	-67	-65	-62	-71	-70	-65	-64	-65	-67	-66	-66	-67	-63	-64	-65	-66	-65	-65	-68	-63	-61	-68	-67	-66	-67	-63	-65	-65	-67	-68	-61	-67	-74	-65	-58	-78	-75	-73	-69	-58	-69	-67	-67	-68	-77	-66	-58	-65	-65	-67	-68	-68	-65	-64	-68	-65	-65	-64	-67	-64	-65	-66	-66	-64	-66	-61	-66	-66	-62	-73	-67	-60	-65	-65	-64	-65	-64	-65	-67	-66	-61	-66	-61	-65	-67	-64	-66	-64	-61	-58	-66	-66	-64	-65	-69	-69	-66	-68	-67	-66	-66	-70	-66	-64	-63	-64	-67	-64	-65"]]

A = []
B = []

num = 3
temp = list(map(int, rss[num][1].split("\t")))
A += temp
B += [rss[num][0]] * (len(temp) - FILTER_SIZE + 1)

data = np.array(A)
output = np.array(B)

def Conv1D_compile(n_filters, SequenceLength, n_features):
    conv_model = tf.keras.Sequential([
        tf.keras.layers.Conv1D(filters=n_filters,
                               kernel_size=FILTER_SIZE,
                               strides=1,
                               padding='valid',
                               input_shape=(SequenceLength, n_features),
                               use_bias=False, name='c1d')])
    conv_model.compile(loss=tf.losses.MeanAbsoluteError(),optimizer=tf.optimizers.Adam(learning_rate=5e-2))
    conv_model.summary()

    return conv_model


def Conv1D_Fit_and_PlotWeights(model, X, y, epochs, n_weights, freq=20):
    w, loss, mae = [], [], []
    for r in range(epochs):
        history = model.fit(X, y, verbose=0)
        if r%freq==0:
            w.append(np.sort(model.layers[0].get_weights()[0].reshape(n_weights)))
            loss.append(history.history['loss'][0])

    w = np.array(w)
    fig, ax = plt.subplots(figsize=(8,4))
    epoch = np.arange(0,len(w))*20
    for n in range(n_weights):
        label = "w_{} -> {}".format(n, n+1)
        ax.axhline(n+1, c='gray', linestyle='--')

    return w

X = data.reshape((1, data.shape[0], 1))
y = output.reshape((1, output.shape[0], 1))

model_cnn = Conv1D_compile(n_filters=1, SequenceLength=len(data), n_features=1)
w = Conv1D_Fit_and_PlotWeights(model=model_cnn, X=X, y=y, epochs=500, n_weights=FILTER_SIZE)

test1 = list(map(int, input("Input RSS: ").split()))
ans = 0
for q in range(len(w[-1])):
    ans += (test1[q] * w[-1][q])

print(ans)



